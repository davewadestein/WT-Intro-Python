{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.socialcops.com/engineering/machine-learning-python/\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's read in the Titanic data for a deeper analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('titanic3.xls', 'titanic3', index_col=None, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legend\n",
    "* pclass = Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "* survived (0 = No; 1 = Yes)\n",
    "* sibsp = number of Siblings/Spouses Aboard\n",
    "* parch = number of Parents/Children Aboard\n",
    "* ticket = ticket Number\n",
    "* embarked (from...C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "* boat = Lifeboat ID\n",
    "* body = ID Number\n",
    "* home.dest = Home/Destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These columns are unlikely to be meaningful and have several missing values so we'll drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['boat', 'ticket', 'cabin', 'body'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can get a quick summary of how many people survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['survived'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because we encode survival as '1', finding the mean will give us a survival percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we group by class and then compute the mean, what does this reveal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('pclass').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas groupby() method essentially creates a bunch of dataframes in which the all the columns match the various values of the grouping variables...\n",
    "* we can see this by looking at the __`groups`__ attribute\n",
    "* each grouping contains the rows of the dataframe\n",
    "* so in the example below, rows 0, 2, 4, 6, 8, etc. are the females in 1st class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['pclass', 'sex']).groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we group by class and gender and compute the mean, what does this tell us about the \"Women\" part of \"Women and children first?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_gender_grouping = data.groupby(['pclass', 'sex']).mean()\n",
    "class_gender_grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's render it as a bar chart to make it clear..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_gender_grouping['survived'].plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we investigate the passengers by age, we can investigate the \"Children\" part of \"Women and children first\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_age = pd.cut(data[\"age\"], np.arange(0, 90, 10))\n",
    "age_grouping = data.groupby(group_by_age).mean()\n",
    "age_grouping['survived'].plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a fair amount of missing values (e.g., __`age`__, __`home.dest`__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can fill in the missing age values with average values. Is this a good strategy for this data? What could we exploit to make a better go of it? (Hint: Look at the class breakdowns above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are basically missing home/destination data and a few embarked results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With only two results missing embarked data, we can probably just drop those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a substantial number of missing home/destination values. We don't know if that is an important feature, but we'd lose a lot of data if we throw those samples away, so let's fill it in with placeholders for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"home.dest\"] = data[\"home.dest\"].fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with only the two embarked rows missing, we are in good shape, so let's drop those and then move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to turn categorical data (__`sex`__ and __`embarked`__) into numbered values using a Sci-Kit Learn __`LabelEncoder`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, model_selection, tree, preprocessing, metrics\n",
    "import sklearn.ensemble as ske\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_titanic_df(df):\n",
    "    processed_df = df.copy()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    processed_df.sex = le.fit_transform(processed_df.sex)\n",
    "    processed_df.embarked = le.fit_transform(processed_df.embarked)\n",
    "    processed_df = processed_df.drop(['name', 'home.dest'],axis=1)\n",
    "    \n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We preprocess our data and then verify that everything is suitable for a learning activity now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = preprocess_titanic_df(data)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The survival data is going to be our target so we drop it from the feature matrix and set up the target matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_df.drop(['survived'], axis=1)\n",
    "y = processed_df['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now split our data into training and test data, create a DecisionTreeClassifier and then see how we do on predictions on survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = tree.DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt.fit(X_train, y_train)\n",
    "clf_dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(clf_dt, out_file=\"titanic.dot\",\n",
    "               feature_names='pclass sex age sibsp parch fare embarked'.split(),\n",
    "               class_names='died survived'.split(),\n",
    "               rounded=True,filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpng titanic.dot -o titanic.png\n",
    "from IPython.display import Image\n",
    "Image('titanic.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the data can sometimes improve our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShuffleSplit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "shuffle_validator = ShuffleSplit(len(X), test_size=0.2, random_state=0)\n",
    "\n",
    "def test_classifier(clf):\n",
    "    scores = cross_val_score(clf, X, y, cv=shuffle_validator)\n",
    "    print(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifier(clf_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A RandomForestClassifier often does better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = ske.RandomForestClassifier(n_estimators=50)\n",
    "test_classifier(clf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other classifiers might do even better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gb = ske.GradientBoostingClassifier(n_estimators=50)\n",
    "test_classifier(clf_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we want to make a specific point, so we'll grab the first twenty rows of each passenger class from our raw data, clean them up and use them as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers_set_1 = data[data.pclass == 1].iloc[:20,:].copy()\n",
    "passengers_set_2 = data[data.pclass == 2].iloc[:20,:].copy()\n",
    "passengers_set_3 = data[data.pclass == 3].iloc[:20,:].copy()\n",
    "passenger_set = pd.concat([passengers_set_1, passengers_set_2, passengers_set_3])\n",
    "testing_set = preprocess_titanic_df(passenger_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normally you wouldn't train and test on the same data, but we're trying to make a point (and this is a closed systemâ€“we're not going to use our model on new, unseen data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.concat([data, passenger_set]).drop_duplicates(keep=False)\n",
    "training_set = preprocess_titanic_df(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_set.drop(['survived'], axis=1).values\n",
    "y = training_set['survived'].values\n",
    "X_test = testing_set.drop(['survived'], axis=1).values\n",
    "y_test = testing_set['survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = ske.RandomForestClassifier(n_estimators=50)\n",
    "clf_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf_rf.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because this is historical data, we can compare predictions to what actually happened.\n",
    "* Models are not destiny!\n",
    "* ...some of the people our model thought would survive didn't and some of the people it thought wouldn't did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_set[passenger_set.survived != prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf.score(X_test, y_test) # 51 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50 /60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
